{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2c6bf8c6c1f747e5b1a85cdbeafa93d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fa9d54b188b4d45b564e411bbe27624",
              "IPY_MODEL_ca548aa6a8f44ad79edb718765fe3217",
              "IPY_MODEL_bf4cca9ba1d04190bd488004820759cc"
            ],
            "layout": "IPY_MODEL_82c224cbd5ee45a5989a2d3937263c75"
          }
        },
        "6fa9d54b188b4d45b564e411bbe27624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63d088ed6db4d0a916adf783638be0a",
            "placeholder": "​",
            "style": "IPY_MODEL_75f9153b219a4be092bd689b641a9fb4",
            "value": "config.json: 100%"
          }
        },
        "ca548aa6a8f44ad79edb718765fe3217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd811d94931462db9e76e22e151dc70",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_826b7ad7653f43429289b874fdbb853e",
            "value": 570
          }
        },
        "bf4cca9ba1d04190bd488004820759cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb8a81a5e0f24d799c7070165fd7300a",
            "placeholder": "​",
            "style": "IPY_MODEL_349c69376fd74d14ad9277f2e8368801",
            "value": " 570/570 [00:00&lt;00:00, 48.2kB/s]"
          }
        },
        "82c224cbd5ee45a5989a2d3937263c75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b63d088ed6db4d0a916adf783638be0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75f9153b219a4be092bd689b641a9fb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd811d94931462db9e76e22e151dc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "826b7ad7653f43429289b874fdbb853e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb8a81a5e0f24d799c7070165fd7300a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349c69376fd74d14ad9277f2e8368801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9c834bce224381ba76509d2ddfa7f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3cb65073e8c64b7785426202828e0fa6",
              "IPY_MODEL_cbdb6917863a49d9aa77773aa18b9493",
              "IPY_MODEL_8fed3eaea31642ba89da5d15d0e328c8"
            ],
            "layout": "IPY_MODEL_be27a2c26d154b1a80a7f2373d780000"
          }
        },
        "3cb65073e8c64b7785426202828e0fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a421b04d96f48959e691ac83f8a24fc",
            "placeholder": "​",
            "style": "IPY_MODEL_a6f60227443d4669b86283e1f246f75f",
            "value": "model.safetensors: 100%"
          }
        },
        "cbdb6917863a49d9aa77773aa18b9493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_073142c6268845fa8841f2f21f5f346e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efd8849906d449ad9686456169617781",
            "value": 440449768
          }
        },
        "8fed3eaea31642ba89da5d15d0e328c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6341fb0490f945fdb48676c9d89555da",
            "placeholder": "​",
            "style": "IPY_MODEL_bfe5faafd1cf4f898d56424c1b5b51a5",
            "value": " 440M/440M [00:06&lt;00:00, 76.7MB/s]"
          }
        },
        "be27a2c26d154b1a80a7f2373d780000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a421b04d96f48959e691ac83f8a24fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6f60227443d4669b86283e1f246f75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "073142c6268845fa8841f2f21f5f346e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efd8849906d449ad9686456169617781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6341fb0490f945fdb48676c9d89555da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe5faafd1cf4f898d56424c1b5b51a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b136f79dd7d4ffbba3970535c506ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f78176c9bb694a82aaa81e338c5c257b",
              "IPY_MODEL_2e403f81d2b54177a3e900b51585d6ac",
              "IPY_MODEL_c8c725e544d449d58789e8f8700bb5b9"
            ],
            "layout": "IPY_MODEL_c69490285d61462e928c2b8bb2edaceb"
          }
        },
        "f78176c9bb694a82aaa81e338c5c257b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6cbef9396ef49788b93e8ed6b5e1e55",
            "placeholder": "​",
            "style": "IPY_MODEL_7bb516b4328c49f6b4c4acf5b112aa69",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2e403f81d2b54177a3e900b51585d6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aa90b2b95be41049836fb607bc94fe2",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a077175ca68546ccaf1f0f3b7302d8c5",
            "value": 48
          }
        },
        "c8c725e544d449d58789e8f8700bb5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1981db5e1629451db9b309bf22ce7a7d",
            "placeholder": "​",
            "style": "IPY_MODEL_91b7afa719a345aea4eac7e6e75f3330",
            "value": " 48.0/48.0 [00:00&lt;00:00, 4.03kB/s]"
          }
        },
        "c69490285d61462e928c2b8bb2edaceb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6cbef9396ef49788b93e8ed6b5e1e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bb516b4328c49f6b4c4acf5b112aa69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aa90b2b95be41049836fb607bc94fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a077175ca68546ccaf1f0f3b7302d8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1981db5e1629451db9b309bf22ce7a7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91b7afa719a345aea4eac7e6e75f3330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1644626ec83146de9f5e3ad2bbc4e937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cbcc71d5a1f4fcfa238c42bf6ca64fe",
              "IPY_MODEL_ef4e56b20a3c4f6ba919100156e2f0b1",
              "IPY_MODEL_1d1d97befddb4de8a7cb5606d9a09b0d"
            ],
            "layout": "IPY_MODEL_33b250ba2a3c460bac5b1038d47d6e02"
          }
        },
        "8cbcc71d5a1f4fcfa238c42bf6ca64fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca62a500dc1549df8e85386d0ad2e0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_f7d185339a1a4d3db9f7c12bcbc72593",
            "value": "vocab.txt: 100%"
          }
        },
        "ef4e56b20a3c4f6ba919100156e2f0b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86292940b544fb2a1c285256f4d765f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_168588ad75ba4abc8bc262853899b93c",
            "value": 231508
          }
        },
        "1d1d97befddb4de8a7cb5606d9a09b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70119988fe8c420ba28903adc2b1f318",
            "placeholder": "​",
            "style": "IPY_MODEL_b3c2083e19fa497bbca4b175c4c59dcf",
            "value": " 232k/232k [00:00&lt;00:00, 8.23MB/s]"
          }
        },
        "33b250ba2a3c460bac5b1038d47d6e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca62a500dc1549df8e85386d0ad2e0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7d185339a1a4d3db9f7c12bcbc72593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a86292940b544fb2a1c285256f4d765f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168588ad75ba4abc8bc262853899b93c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70119988fe8c420ba28903adc2b1f318": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3c2083e19fa497bbca4b175c4c59dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38f5211b80af41ccbe5abb1dd2269300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7271586fcafc480882a361a74fcd7b37",
              "IPY_MODEL_b395b65cc4cb4a2c9bde38c977c10f3b",
              "IPY_MODEL_68fc5b39a17d48aeaf8a57b7da035c23"
            ],
            "layout": "IPY_MODEL_d90f2c0843b644a6bce90edc31ab24a0"
          }
        },
        "7271586fcafc480882a361a74fcd7b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bdb94a4757e4818a703e3a8548d1f11",
            "placeholder": "​",
            "style": "IPY_MODEL_b9ad8030c62c4bcb998f614d11c7182c",
            "value": "tokenizer.json: 100%"
          }
        },
        "b395b65cc4cb4a2c9bde38c977c10f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be6943c00db341a98e094359cfc1f7e1",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b97c522995049b4ba94db70b7799c44",
            "value": 466062
          }
        },
        "68fc5b39a17d48aeaf8a57b7da035c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13e39e9dba14a2785ced9161cce9d25",
            "placeholder": "​",
            "style": "IPY_MODEL_b00ddfd330f64d2a90be58d6afb6a3a4",
            "value": " 466k/466k [00:00&lt;00:00, 12.0MB/s]"
          }
        },
        "d90f2c0843b644a6bce90edc31ab24a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bdb94a4757e4818a703e3a8548d1f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ad8030c62c4bcb998f614d11c7182c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be6943c00db341a98e094359cfc1f7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b97c522995049b4ba94db70b7799c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f13e39e9dba14a2785ced9161cce9d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00ddfd330f64d2a90be58d6afb6a3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz9HrFvhNFev",
        "outputId": "17290400-6f42-46bc-c780-9aaf1569ef85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAMQA'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 81 (delta 30), reused 58 (delta 19), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (81/81), 251.91 KiB | 9.00 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TonyBY/RAMQA.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDDbOyrJNG5C",
        "outputId": "e40287fb-e289-46ef-88ab-3b2cd838e7a6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/RAMQA/src/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trUEtp8wNMLU",
        "outputId": "33678f98-48e3-4923-d41b-f571481cb6ee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.41.2 (from -r /content/RAMQA/src/requirements.txt (line 1))\n",
            "  Downloading bitsandbytes-0.41.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting comet-ml==3.35.1 (from -r /content/RAMQA/src/requirements.txt (line 2))\n",
            "  Downloading comet_ml-3.35.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting cytoolz==0.12.2 (from -r /content/RAMQA/src/requirements.txt (line 3))\n",
            "  Downloading cytoolz-0.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting datasets==2.14.6 (from -r /content/RAMQA/src/requirements.txt (line 4))\n",
            "  Downloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting deepspeed==0.11.1 (from -r /content/RAMQA/src/requirements.txt (line 5))\n",
            "  Downloading deepspeed-0.11.1.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps -r /content/RAMQA/src/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFWmWU6RNWy3",
        "outputId": "87741bb3-4773-419d-8fae-1b4287d57459"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes==0.41.2 (from -r /content/RAMQA/src/requirements.txt (line 1))\n",
            "  Using cached bitsandbytes-0.41.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting comet-ml==3.35.1 (from -r /content/RAMQA/src/requirements.txt (line 2))\n",
            "  Using cached comet_ml-3.35.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting cytoolz==0.12.2 (from -r /content/RAMQA/src/requirements.txt (line 3))\n",
            "  Using cached cytoolz-0.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting datasets==2.14.6 (from -r /content/RAMQA/src/requirements.txt (line 4))\n",
            "  Using cached datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting deepspeed==0.11.1 (from -r /content/RAMQA/src/requirements.txt (line 5))\n",
            "  Using cached deepspeed-0.11.1.tar.gz (1.1 MB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jsonlines==4.0.0 lightning==2.1.0 pandas==2.1.2 peft==0.6.0 pickle5==0.0.11 pyserini==0.22.1 scipy==1.11.3 sentencepiece==0.1.99 spacy==3.7.2 tensorboard==2.15.0 torch==2.1.0 torchvision==0.16.0 tqdm==4.66.1 transformers==4.34.1 trl==0.7.4 unsloth==2024.4 wordcloud==1.9.2 word2number==1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DzjH1hBNpCH",
        "outputId": "7a535a4f-60fb-4a95-9074-2b3ef25510bf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jsonlines==4.0.0\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting lightning==2.1.0\n",
            "  Downloading lightning-2.1.0-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas==2.1.2\n",
            "  Downloading pandas-2.1.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting peft==0.6.0\n",
            "  Downloading peft-0.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting pickle5==0.0.11\n",
            "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.1/132.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyserini==0.22.1\n",
            "  Downloading pyserini-0.22.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting scipy==1.11.3\n",
            "  Downloading scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece==0.1.99\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting spacy==3.7.2\n",
            "  Downloading spacy-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting tensorboard==2.15.0\n",
            "  Downloading tensorboard-2.15.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting torch==2.1.0\n",
            "  Downloading torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision==0.16.0\n",
            "  Downloading torchvision-0.16.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tqdm==4.66.1\n",
            "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.34.1\n",
            "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl==0.7.4\n",
            "  Downloading trl-0.7.4-py3-none-any.whl.metadata (10 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.0.12 Requires-Python >=3.5, <3.8; 1.6.2 Requires-Python >=3.7,<3.10; 1.6.3 Requires-Python >=3.7,<3.10; 1.7.0 Requires-Python >=3.7,<3.10; 1.7.1 Requires-Python >=3.7,<3.10; 1.7.2 Requires-Python >=3.7,<3.11; 1.7.3 Requires-Python >=3.7,<3.11; 1.8.0 Requires-Python >=3.8,<3.11; 1.8.0rc1 Requires-Python >=3.8,<3.11; 1.8.0rc2 Requires-Python >=3.8,<3.11; 1.8.0rc3 Requires-Python >=3.8,<3.11; 1.8.0rc4 Requires-Python >=3.8,<3.11; 1.8.1 Requires-Python >=3.8,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement unsloth==2024.4 (from versions: 2024.8, 2024.9, 2024.9.post1, 2024.9.post2, 2024.9.post3, 2024.9.post4, 2024.10.0, 2024.10.1, 2024.10.2, 2024.10.4, 2024.10.5, 2024.10.6, 2024.10.7, 2024.11.2, 2024.11.4, 2024.11.5, 2024.11.6, 2024.11.7, 2024.11.8, 2024.11.9, 2024.11.10, 2024.11.11, 2024.12.1, 2024.12.2, 2024.12.3, 2024.12.4, 2024.12.5, 2024.12.6, 2024.12.7, 2024.12.8, 2024.12.9, 2024.12.10, 2024.12.11, 2024.12.12, 2025.1.1, 2025.1.2, 2025.1.3, 2025.1.4, 2025.1.5, 2025.1.6, 2025.1.8, 2025.2.2, 2025.2.3, 2025.2.4, 2025.2.5, 2025.2.6, 2025.2.7, 2025.2.8, 2025.2.9, 2025.2.10, 2025.2.11, 2025.2.12, 2025.2.13, 2025.2.14, 2025.2.15, 2025.3.1, 2025.3.2, 2025.3.3, 2025.3.4, 2025.3.5, 2025.3.6, 2025.3.7, 2025.3.8, 2025.3.9, 2025.3.10, 2025.3.11, 2025.3.12, 2025.3.13, 2025.3.14, 2025.3.15, 2025.3.16, 2025.3.17, 2025.3.18, 2025.3.19, 2025.4.1, 2025.4.2, 2025.4.3, 2025.4.4, 2025.4.5, 2025.4.7, 2025.5.1, 2025.5.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for unsloth==2024.4\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth==2024.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hIftqzeOWu9",
        "outputId": "7f767253-a4d9-43a2-f814-288b9cd8d764"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement unsloth==2024.4 (from versions: 2024.8, 2024.9, 2024.9.post1, 2024.9.post2, 2024.9.post3, 2024.9.post4, 2024.10.0, 2024.10.1, 2024.10.2, 2024.10.4, 2024.10.5, 2024.10.6, 2024.10.7, 2024.11.2, 2024.11.4, 2024.11.5, 2024.11.6, 2024.11.7, 2024.11.8, 2024.11.9, 2024.11.10, 2024.11.11, 2024.12.1, 2024.12.2, 2024.12.3, 2024.12.4, 2024.12.5, 2024.12.6, 2024.12.7, 2024.12.8, 2024.12.9, 2024.12.10, 2024.12.11, 2024.12.12, 2025.1.1, 2025.1.2, 2025.1.3, 2025.1.4, 2025.1.5, 2025.1.6, 2025.1.8, 2025.2.2, 2025.2.3, 2025.2.4, 2025.2.5, 2025.2.6, 2025.2.7, 2025.2.8, 2025.2.9, 2025.2.10, 2025.2.11, 2025.2.12, 2025.2.13, 2025.2.14, 2025.2.15, 2025.3.1, 2025.3.2, 2025.3.3, 2025.3.4, 2025.3.5, 2025.3.6, 2025.3.7, 2025.3.8, 2025.3.9, 2025.3.10, 2025.3.11, 2025.3.12, 2025.3.13, 2025.3.14, 2025.3.15, 2025.3.16, 2025.3.17, 2025.3.18, 2025.3.19, 2025.4.1, 2025.4.2, 2025.4.3, 2025.4.4, 2025.4.5, 2025.4.7, 2025.5.1, 2025.5.2)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for unsloth==2024.4\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud==1.9.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDvyrZBMOuMB",
        "outputId": "141d1e30-2e79-443b-dc57-e313390fbf18"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wordcloud==1.9.2\n",
            "  Downloading wordcloud-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from wordcloud==1.9.2) (2.0.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud==1.9.2) (11.2.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from wordcloud==1.9.2) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->wordcloud==1.9.2) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud==1.9.2) (1.17.0)\n",
            "Downloading wordcloud-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (473 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m473.1/473.1 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wordcloud\n",
            "  Attempting uninstall: wordcloud\n",
            "    Found existing installation: wordcloud 1.9.4\n",
            "    Uninstalling wordcloud-1.9.4:\n",
            "      Successfully uninstalled wordcloud-1.9.4\n",
            "Successfully installed wordcloud-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word2number==1.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSeXpkDGOw57",
        "outputId": "e6652713-3edc-4e04-a3b9-2c5f18607360"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word2number==1.1\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: word2number\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=2ab58cd4664034876ecb0ccdf5a632330736a61e3c5a9fc94fab565ec718f482\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built word2number\n",
            "Installing collected packages: word2number\n",
            "Successfully installed word2number-1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/RAMQA/src/utils/data_loader.py\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Utility function to load data from a CSV or JSON file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"Data file not found: {file_path}\")\n",
        "\n",
        "    file_extension = file_path.split('.')[-1]\n",
        "\n",
        "    if file_extension == 'csv':\n",
        "        return pd.read_csv(file_path)\n",
        "    elif file_extension == 'json':\n",
        "        return pd.read_json(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_extension}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9kC0QuYOzyO",
        "outputId": "c94dc212-3b42-42f7-afd7-f4eca2aac8c2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/RAMQA/src/utils/data_loader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/RAMQA/src')"
      ],
      "metadata": {
        "id": "Ia0zPXN7QLwh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_loader import load_data"
      ],
      "metadata": {
        "id": "zbTKK0huS_Fa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9QcJP7i2WZN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyUh26qBUB-H",
        "outputId": "adb13e1c-2c98-4754-d97f-38df35e3b07f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "C340dejEhEcv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since the zip file is already extracted, let's inspect the contents of the directory structure again to ensure we are working with the right files.\n",
        "\n",
        "# Listing files in the 'RAMQA-main' directory to verify\n",
        "ramqa_folder_path = '/content/RAMQA'\n",
        "\n",
        "ramqa_files = os.listdir(ramqa_folder_path)\n",
        "ramqa_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GxrA1DthIIH",
        "outputId": "d2fad688-dfb6-4de5-8932-361375a83a2c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imgs',\n",
              " 'README.md',\n",
              " '.git',\n",
              " '.gitignore',\n",
              " 'LICENSE',\n",
              " '.gitmodules',\n",
              " 'src',\n",
              " 'download_data.sh']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's correct the file path and proceed with listing the files in the 'src' directory.\n",
        "ramqa_main_folder_path = '/content/RAMQA'\n",
        "\n",
        "# Now let's list files in the 'src' directory\n",
        "src_folder_path = os.path.join(ramqa_main_folder_path, 'src')\n",
        "src_files = os.listdir(src_folder_path)\n",
        "src_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsfIgrLVheiR",
        "outputId": "42112a5b-7a2b-4ba5-8a68-298efac2e24e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RankLLaVA', 'RAMLLaMA', 'requirements.txt', 'utils']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now open the 'RAMLLaMA' folder and list the files inside to locate 'train_RAMLLaMA.py'.\n",
        "ramllama_folder_path = os.path.join(src_folder_path, 'RAMLLaMA')\n",
        "\n",
        "# List files in the 'RAMLLaMA' directory\n",
        "ramllama_files = os.listdir(ramllama_folder_path)\n",
        "ramllama_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4xz38VmiuGf",
        "outputId": "cf5dec07-34ab-4c61-8357-860da0976e81"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train_RAMLLaMA.py', 'eval', 'data']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change 1"
      ],
      "metadata": {
        "id": "tmboV2IxMW9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the directory exists before saving the file\n",
        "os.makedirs('/mnt/data', exist_ok=True)\n",
        "\n",
        "# Define the correct path to save the updated file\n",
        "updated_ramllama_path = '/mnt/data/updated_train_RAMLLaMA.py'\n",
        "\n",
        "# Save the updated code to the correct file path\n",
        "with open(updated_ramllama_path, 'w') as file:\n",
        "    file.write(updated_ramllama_code)\n",
        "\n",
        "updated_ramllama_path  # Return the path to the updated file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "MnJmxZrbjkbM",
        "outputId": "952873fe-e6f7-432d-e952-60f72080f3ce"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/mnt/data/updated_train_RAMLLaMA.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's read and display the contents of the updated 'train_RAMLLaMA.py' file to check the modifications.\n",
        "with open(train_ramllama_path, 'r') as file:\n",
        "    updated_ramllama_code = file.read()\n",
        "\n",
        "updated_ramllama_code[:2000]  # Display the first 2000 characters of the file content for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "tXzJ9qJZjnrD",
        "outputId": "580e9715-0ecc-443f-8450-97e2134f1348"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from __future__ import absolute_import\\nfrom __future__ import division\\nfrom __future__ import print_function\\nfrom __future__ import unicode_literals\\n\\nimport os\\nimport sys\\n\\npwd = os.getcwd()\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-6]))\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-5]))\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-4]))\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-3]))\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-2]))\\nsys.path.append(\\'/\\'.join(pwd.split(\\'/\\')[:-1]))\\n\\nos.environ[\\n        \"TORCH_DISTRIBUTED_DEBUG\"\\n    ] = \"DETAIL\"  # set to DETAIL for runtime logging.\\nos.environ[\\'FLAGS_eager_delete_tensor_gb\\'] = \\'0\\'  # enable gc\\nos.environ[\\'TOKENIZERS_PARALLELISM\\'] = \\'false\\'\\n\\nfrom datasets import Dataset, DatasetDict\\nimport numpy as np\\nimport logging\\nfrom PIL import ImageFile\\nimport pathlib\\nimport random\\n\\nimport torch\\nimport transformers\\nfrom transformers import TrainingArguments, EarlyStoppingCallback\\n\\nfrom trl import SFTTrainer\\n\\nfrom unsloth import FastLanguageModel\\n\\nfrom RAMQA.src.utils.config import parser\\nfrom RAMQA.src.utils.args import prepare_logger\\nfrom RAMQA.src.utils.data_utils import read_jsonl, make_directory\\n\\nnp.set_printoptions(precision=4)\\nImageFile.LOAD_TRUNCATED_IMAGES = True\\n\\ntransformers.logging.set_verbosity_error()\\nos.environ[\\'FLAGS_eager_delete_tensor_gb\\'] = \\'0\\'  # enable gc\\n\\nargs = parser.parse_args()\\nlogger = logging.getLogger()\\n\\ntorch.cuda.empty_cache()\\ntorch.set_float32_matmul_precision(\\'medium\\')\\n\\n\\ndef train(args):\\n    random.seed(args.seed)\\n    np.random.seed(args.seed)\\n    torch.manual_seed(args.seed)\\n\\n    # 1. Load Dataset\\n    training_data = read_jsonl(args.train_file)\\n    val_data = read_jsonl(args.development_file)\\n\\n    if args.debug:\\n        training_data = training_data[:(int(args.train_batch_size) * int(args.accumulate_gradients))]\\n        val_data = val_data[:int(args.train_batch_size)]\\n\\n    traing_dataset = Dataset.from_list(training_data)\\n    val_dataset = Dataset.from_list(val_data)\\n\\n    dataset = DatasetDict({\\n                '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the next portion of the file content after the first 2000 characters.\n",
        "updated_ramllama_code[2000:4000]  # Display characters from position 2000 to 4000 for inspection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "4mpUB-tGmC20",
        "outputId": "05898fe3-127f-4490-81ae-2a89ef700023"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'        \\'train\\': traing_dataset,\\n                        \\'validation\\': val_dataset,\\n                    })\\n    \\n    logger.info(f\"dataset: {dataset}\")\\n\\n    total_steps = len(training_data) // (int(args.train_batch_size) * int(args.accumulate_gradients))\\n    eval_steps = total_steps // args.patience\\n\\n    logger.info(f\"len(train_dataset): {len(training_data)}\")\\n    logger.info(f\"int(args.train_batch_size): {int(args.train_batch_size)}\")\\n    logger.info(f\"int(args.accumulate_gradients): {int(args.accumulate_gradients)}\")\\n    logger.info(f\"total_steps / Epoch: {total_steps}\")\\n    logger.info(f\"args.patience: {args.patience}\")\\n    logger.info(f\"eval_steps: {eval_steps}\")\\n\\n    \\n    # 2. Load Llama3 model\\n    model, tokenizer = FastLanguageModel.from_pretrained(\\n        model_name = args.llama_model_name,\\n        max_seq_length = args.max_seq_len,\\n        dtype = None,\\n        load_in_4bit = args.bits == 4,\\n    )\\n\\n    # 3 Before training\\n    def generate_text(text):\\n        inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda:0\")\\n        outputs = model.generate(**inputs, max_new_tokens=100)\\n        logger.info(tokenizer.decode(outputs[0], skip_special_tokens=True))\\n\\n    logger.info(\"Before training\\\\n\")\\n    generate_text(val_dataset[0][\\'text\\'].split(\\'### Response:\\')[0] + \\'### Response:\\\\n        \\')\\n\\n    # 4. Do model patching and add fast LoRA weights and training\\n    model = FastLanguageModel.get_peft_model(\\n                                                model,\\n                                                r = args.lora_r,\\n                                                target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\\n                                                                \"gate_proj\", \"up_proj\", \"down_proj\",],\\n                                                lora_alpha = args.lora_alpha,\\n                                                lora_dropout = args.lora_dropout, # Supports any, but = 0 is optimized\\n                                               '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path in Google Colab environment where you want to store the file\n",
        "folder_path = '/content/RAMQA/src/RAMLLaVA'\n",
        "\n",
        "# Ensure the folder exists\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Define the full path for the file\n",
        "file_path = os.path.join(folder_path, 'train_RAMLLaMA_updated.py')\n",
        "\n",
        "# Write the code to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(code)\n",
        "\n",
        "file_path  # Return the path to the file in the specified folder in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "WUnHg3TkyyEs",
        "outputId": "322a6b2d-2230-46bf-adad-96e232f82c19"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RAMQA/src/RAMLLaVA/train_RAMLLaMA_updated.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where the file should be saved\n",
        "file_path = '/mnt/data/train_RAMLLaMA_updated.py'\n",
        "\n",
        "# Define the code as a multi-line string (you can paste the entire code here)\n",
        "code = \"\"\"\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "pwd = os.getcwd()\n",
        "sys.path.append('/'.join(pwd.split('/')[:-6]))\n",
        "sys.path.append('/'.join(pwd.split('/')[:-5]))\n",
        "sys.path.append('/'.join(pwd.split('/')[:-4]))\n",
        "sys.path.append('/'.join(pwd.split('/')[:-3]))\n",
        "sys.path.append('/'.join(pwd.split('/')[:-2]))\n",
        "sys.path.append('/'.join(pwd.split('/')[:-1]))\n",
        "\n",
        "os.environ[\n",
        "        \"TORCH_DISTRIBUTED_DEBUG\"\n",
        "    ] = \"DETAIL\"  # set to DETAIL for runtime logging.\n",
        "os.environ['FLAGS_eager_delete_tensor_gb'] = '0'  # enable gc\n",
        "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "import numpy as np\n",
        "import logging\n",
        "from PIL import ImageFile\n",
        "import pathlib\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "from transformers import TrainingArguments, EarlyStoppingCallback\n",
        "\n",
        "from trl import SFTTrainer\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "from RAMQA.src.utils.config import parser\n",
        "from RAMQA.src.utils.args import prepare_logger\n",
        "from RAMQA.src.utils.data_utils import read_jsonl, make_directory\n",
        "\n",
        "np.set_printoptions(precision=4)\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "transformers.logging.set_verbosity_error()\n",
        "os.environ['FLAGS_eager_delete_tensor_gb'] = '0'  # enable gc\n",
        "\n",
        "args = parser.parse_args()\n",
        "logger = logging.getLogger()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.set_float32_matmul_precision('medium')\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    random.seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    torch.manual_seed(args.seed)\n",
        "\n",
        "    # 1. Load Dataset\n",
        "    training_data = read_jsonl(args.train_file)\n",
        "    val_data = read_jsonl(args.development_file)\n",
        "\n",
        "    if args.debug:\n",
        "        training_data = training_data[:(int(args.train_batch_size) * int(args.accumulate_gradients))]\n",
        "        val_data = val_data[:int(args.train_batch_size)]\n",
        "\n",
        "    traing_dataset = Dataset.from_list(training_data)\n",
        "    val_dataset = Dataset.from_list(val_data)\n",
        "\n",
        "    dataset = DatasetDict({\n",
        "                        'train': traing_dataset,\n",
        "                        'validation': val_dataset,\n",
        "                    })\n",
        "\n",
        "    logger.info(f\"dataset: {dataset}\")\n",
        "\n",
        "    total_steps = len(training_data) // (int(args.train_batch_size) * int(args.accumulate_gradients))\n",
        "    eval_steps = total_steps // args.patience\n",
        "\n",
        "    logger.info(f\"len(train_dataset): {len(training_data)}\")\n",
        "    logger.info(f\"int(args.train_batch_size): {int(args.train_batch_size)}\")\n",
        "    logger.info(f\"int(args.accumulate_gradients): {int(args.accumulate_gradients)}\")\n",
        "    logger.info(f\"total_steps / Epoch: {total_steps}\")\n",
        "    logger.info(f\"args.patience: {args.patience}\")\n",
        "    logger.info(f\"eval_steps: {eval_steps}\")\n",
        "\n",
        "\n",
        "    # 2. Load Llama3 model\n",
        "    model, tokenizer = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name = args.llama_model_name,\n",
        "        max_seq_length = args.max_seq_len,\n",
        "        dtype = None,\n",
        "        load_in_4bit = args.bits == 4,\n",
        "    )\n",
        "\n",
        "    # 3 Before training\n",
        "    def generate_text(text):\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "        outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "        logger.info(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "    logger.info(\"Before training\\n\")\n",
        "    generate_text(val_dataset[0]['text'].split('### Response:')[0] + '### Response:\\n        ')\n",
        "\n",
        "    # 4. Do model patching and add fast LoRA weights and training\n",
        "    model = AutoModelForSequenceClassification.get_peft_model(\n",
        "                                                model,\n",
        "                                                r = args.lora_r,\n",
        "                                                target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                                                                \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "                                                lora_alpha = args.lora_alpha,\n",
        "                                                lora_dropout = args.lora_dropout, # Supports any, but = 0 is optimized\n",
        "                                                bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "                                                use_gradient_checkpointing = args.gradient_checkpointing,\n",
        "                                                random_state = args.seed,\n",
        "                                                max_seq_length = args.max_seq_len,\n",
        "                                                use_rslora = False,  # Rank stabilized LoRA\n",
        "                                                loftq_config = None, # LoftQ\n",
        "                                            )\n",
        "\n",
        "    # Set training parameters\n",
        "    training_arguments = TrainingArguments(\n",
        "        output_dir=args.output_dir,\n",
        "        evaluation_strategy=\"steps\",\n",
        "        num_train_epochs=1 if args.debug else args.num_train_epochs,\n",
        "        per_device_train_batch_size=args.train_batch_size,\n",
        "        per_device_eval_batch_size=int(1 * args.train_batch_size),\n",
        "        gradient_accumulation_steps=args.accumulate_gradients,\n",
        "        # optim='paged_adamw_32bit',\n",
        "        optim=\"adamw_8bit\",\n",
        "        eval_steps=1 if args.debug else eval_steps,\n",
        "        save_steps=1 if args.debug else eval_steps, # Save checkpoint every X updates steps\n",
        "        save_total_limit=1,\n",
        "        eval_delay=0,\n",
        "        # logging_steps=1 if args.debug else 100,\n",
        "        logging_steps=1,\n",
        "        learning_rate=args.learning_rate,\n",
        "        weight_decay=args.weight_decay,\n",
        "        bf16=True if torch.cuda.is_bf16_supported() else False,\n",
        "        fp16=False if torch.cuda.is_bf16_supported() else True,\n",
        "        max_grad_norm=0.3,                          # Maximum gradient normal (gradient clipping)\n",
        "        max_steps=-1,                               # Number of training steps (overrides num_train_epochs)\n",
        "        # warmup_ratio=0.03,                          # Ratio of steps for a linear warmup (from 0 to learning rate)\n",
        "        warmup_steps = args.warmup_steps,\n",
        "        group_by_length=True,                       # Group sequences into batches with same length; Saves memory and speeds up training considerably\n",
        "        # lr_scheduler_type='cosine',                 # Learning rate schedule\n",
        "        lr_scheduler_type='linear',                 # Learning rate schedule\n",
        "        report_to=\"wandb\",\n",
        "        # report_to=\"tensorboard\",\n",
        "        load_best_model_at_end=True,\n",
        "        gradient_checkpointing=args.gradient_checkpointing,\n",
        "        gradient_checkpointing_kwargs={'use_reentrant': args.use_reentrant},\n",
        "        disable_tqdm=False,\n",
        "        seed=args.seed,\n",
        "        # hub_token=args.huggingface_token,\n",
        "    )\n",
        "\n",
        "    # Set supervised fine-tuning parameters\n",
        "    trainer = SFTTrainer(\n",
        "        model=model,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"validation\"],\n",
        "        dataset_text_field=\"text\",\n",
        "        max_seq_length=args.max_seq_len,\n",
        "        tokenizer=tokenizer,\n",
        "        args=training_arguments,\n",
        "    )\n",
        "\n",
        "    trainer.add_callback(EarlyStoppingCallback(args.patience, 0.0))\n",
        "\n",
        "    logger.info(f\"trainer.args: {trainer.args}\")\n",
        "\n",
        "    # Train model\n",
        "    logger.info(\"Start training...\")\n",
        "    if list(pathlib.Path(args.output_dir).glob(\"checkpoint-*\")) and not args.debug:\n",
        "        trainer.train(resume_from_checkpoint=True)\n",
        "    else:\n",
        "        trainer.train()\n",
        "\n",
        "    # 5. After training\n",
        "    logger.info(\"\\n ######## \\nAfter training\\n\")\n",
        "    generate_text(val_dataset[0]['text'].split('### Response:')[0] + '### Response:\\n        ')\n",
        "\n",
        "    # Save trained model\n",
        "    trainer.save_state()\n",
        "    trainer.model.save_pretrained(os.path.join(args.output_dir, str(args.llama_model_name).split('/')[-1] + '_ramqa'))\n",
        "\n",
        "if __name__=='__main__':\n",
        "    make_directory(args.output_dir)\n",
        "    prepare_logger(logger, debug=args.debug, save_to_file=os.path.join(args.output_dir, \"llama3_ramqa_training.log\"))\n",
        "    logger.info(args)\n",
        "    train(args)\n",
        "    logger.info(\"ALL DONE!\")\n",
        "\"\"\"\n",
        "\n",
        "# Write the code to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(code)\n",
        "\n",
        "# Return the file path for user download\n",
        "file_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vyoq-SIBm-hz",
        "outputId": "3c574803-91fb-4af8-90fe-c001f211108e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/mnt/data/train_RAMLLaMA_updated.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change 2"
      ],
      "metadata": {
        "id": "4TXvMFTCMbsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.amp import autocast, GradScaler"
      ],
      "metadata": {
        "id": "_1thtBCKz-Rw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the folder path where the file will be stored in Colab\n",
        "folder_path = '/content/RAMQA/src/RAMLLaVA'\n",
        "\n",
        "# Ensure the folder exists\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# Define the full path for the new file\n",
        "file_path = os.path.join(folder_path, 'updated_train_RAMLLaMA.py')\n",
        "\n",
        "# Write the code into the new Python file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.write(\"\"\"\n",
        "import torch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from transformers import AdamW, AutoModelForSequenceClassification, AutoTokenizer\n",
        "from datasets import Dataset\n",
        "\n",
        "# Initialize GradScaler for mixed precision\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Initialize your model and optimizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(args.llama_model_name)\n",
        "model.to(device)  # Ensure the model is moved to the GPU\n",
        "optimizer = AdamW(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "# Training loop with mixed precision\n",
        "for epoch in range(args.num_train_epochs):\n",
        "    model.train()\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        # Move data to GPU\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        # Forward pass with mixed precision (autocast ensures FP16 where possible)\n",
        "        with autocast():  # Use mixed precision in forward pass\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "        # Backward pass with scaled loss (GradScaler scales gradients for FP16)\n",
        "        scaler.scale(loss).backward()  # Scales the loss to prevent underflow\n",
        "\n",
        "        # Optimizer step\n",
        "        scaler.step(optimizer)  # Step the optimizer with scaled gradients\n",
        "        scaler.update()  # Update the scaler for next iteration\n",
        "\n",
        "        # Zero gradients after optimizer step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    # Log training loss for the current epoch\n",
        "    logger.info(f\"Epoch {epoch} - Loss: {loss.item()}\")\n",
        "\n",
        "# After training, save the model\n",
        "model.save_pretrained(args.output_dir)\n",
        "\"\"\")\n",
        "\n",
        "file_path  # Return the path to the new file for access in Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1HTtMqdkMhVO",
        "outputId": "971613fb-2b51-4f82-d524-aa77f2836b8d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RAMQA/src/RAMLLaVA/updated_train_RAMLLaMA.py'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change 3"
      ],
      "metadata": {
        "id": "HoDN4FArRynu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the base directory and folder paths\n",
        "base_dir = '/content/RAMQA/src/RAMLLaVA'\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(base_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "37Bgkpp5VjFC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# model.py: Model architecture definition\n",
        "model_code = \"\"\"\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "def build_model(model_name, max_seq_len, load_in_4bit=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Builds and returns the model and tokenizer.\n",
        "    \\\"\\\"\\\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        max_seq_length=max_seq_len,\n",
        "        load_in_4bit=load_in_4bit\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    return model, tokenizer\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gj5rozqaWDcu"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_processing.py: Data loading and preprocessing\n",
        "data_processing_code = \"\"\"\n",
        "from datasets import Dataset\n",
        "\n",
        "def load_data(train_file, val_file, batch_size, debug=False):\n",
        "    \\\"\\\"\\\"\n",
        "    Loads training and validation datasets, and prepares them for training.\n",
        "    \\\"\\\"\\\"\n",
        "    training_data = read_jsonl(train_file)\n",
        "    val_data = read_jsonl(val_file)\n",
        "\n",
        "    if debug:\n",
        "        training_data = training_data[:(batch_size * 2)]  # Reduce data for debugging\n",
        "        val_data = val_data[:batch_size]\n",
        "\n",
        "    train_dataset = Dataset.from_list(training_data)\n",
        "    val_dataset = Dataset.from_list(val_data)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-vU-SF95WGBP"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py: Training loop with mixed precision\n",
        "train_code = \"\"\"\n",
        "import torch\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from transformers import AdamW\n",
        "from model import build_model\n",
        "from data_processing import load_data\n",
        "\n",
        "def train_model(args):\n",
        "    \\\"\\\"\\\"\n",
        "    Handles model training with mixed precision.\n",
        "    \\\"\\\"\\\"\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Load data and model\n",
        "    train_dataset, val_dataset = load_data(args.train_file, args.development_file, args.train_batch_size, args.debug)\n",
        "    model, tokenizer = build_model(args.llama_model_name, args.max_seq_len, args.bits == 4)\n",
        "\n",
        "    model.to(args.device)\n",
        "    optimizer = AdamW(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "    for epoch in range(args.num_train_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for batch in train_dataset:\n",
        "            input_ids = batch['input_ids'].to(args.device)\n",
        "            attention_mask = batch['attention_mask'].to(args.device)\n",
        "            labels = batch['labels'].to(args.device)\n",
        "\n",
        "            with autocast():\n",
        "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        print(f\"Epoch {epoch+1} completed\")\n",
        "\n",
        "    model.save_pretrained(args.output_dir)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "jYg2Kzq4WJCa"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate.py: Evaluation logic\n",
        "evaluate_code = \"\"\"\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def evaluate_model(model, val_dataset, tokenizer, device):\n",
        "    \\\"\\\"\\\"\n",
        "    Evaluate the model on the validation set.\n",
        "    \\\"\\\"\\\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in val_dataset:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            preds = torch.argmax(logits, dim=-1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iCtYWzybWSxp"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py: Logging and config setup\n",
        "utils_code = \"\"\"\n",
        "import logging\n",
        "\n",
        "def setup_logging():\n",
        "    \\\"\\\"\\\"\n",
        "    Sets up logging for training and evaluation.\n",
        "    \\\"\\\"\\\"\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger()\n",
        "    return logger\n",
        "\n",
        "def setup_config():\n",
        "    \\\"\\\"\\\"\n",
        "    Sets up the configuration dictionary with default values for training.\n",
        "    \\\"\\\"\\\"\n",
        "    config = {\n",
        "        'train_batch_size': 16,\n",
        "        'num_train_epochs': 3,\n",
        "        'learning_rate': 5e-5,\n",
        "        'output_dir': './output',\n",
        "        'llama_model_name': 'bert-base-uncased',\n",
        "        'max_seq_len': 128,\n",
        "        'bits': 16,\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "        'train_file': './data/train.json',\n",
        "        'development_file': './data/val.json'\n",
        "    }\n",
        "    return config\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "B7Sq-qzxWWAC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py: Main entry point to tie everything together\n",
        "main_code = \"\"\"\n",
        "from train import train_model\n",
        "from utils import setup_logging, setup_config\n",
        "\n",
        "logger = setup_logging()\n",
        "\n",
        "# Setup config\n",
        "config = setup_config()\n",
        "\n",
        "logger.info(\"Starting model training...\")\n",
        "train_model(config)\n",
        "logger.info(\"Training completed.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4W1vtQEoWaxP"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "with open(os.path.join(base_dir, 'model.py'), 'w') as file:\n",
        "    file.write(model_code)"
      ],
      "metadata": {
        "id": "_J3Dxf5EWdGW"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_processing.py\n",
        "with open(os.path.join(base_dir, 'data_processing.py'), 'w') as file:\n",
        "    file.write(data_processing_code)"
      ],
      "metadata": {
        "id": "aoD8vkFRWff7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "with open(os.path.join(base_dir, 'train.py'), 'w') as file:\n",
        "    file.write(train_code)"
      ],
      "metadata": {
        "id": "ybqlAaKAWiZx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate.py\n",
        "with open(os.path.join(base_dir, 'evaluate.py'), 'w') as file:\n",
        "    file.write(evaluate_code)"
      ],
      "metadata": {
        "id": "53JqPKYPWl7U"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "with open(os.path.join(base_dir, 'utils.py'), 'w') as file:\n",
        "    file.write(utils_code)"
      ],
      "metadata": {
        "id": "8qcsDu_1Wo3F"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "with open(os.path.join(base_dir, 'main.py'), 'w') as file:\n",
        "    file.write(main_code)"
      ],
      "metadata": {
        "id": "n4g9b4vMWsOP"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2HiJSrxfWu4c",
        "outputId": "20a7d0b2-44ce-4fb0-96e0-00d44bbf24c1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RAMQA/src/RAMLLaVA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "change 4"
      ],
      "metadata": {
        "id": "v0wD2OrlXI1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace this:\n",
        "# from unsloth import FastLanguageModel\n",
        "\n",
        "# With Hugging Face:\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ],
      "metadata": {
        "id": "tFGLFerOXDxz"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Old code using `unsloth`:\n",
        "# model = FastLanguageModel.from_pretrained('model_name')\n",
        "\n",
        "# New code using Hugging Face:\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "2c6bf8c6c1f747e5b1a85cdbeafa93d5",
            "6fa9d54b188b4d45b564e411bbe27624",
            "ca548aa6a8f44ad79edb718765fe3217",
            "bf4cca9ba1d04190bd488004820759cc",
            "82c224cbd5ee45a5989a2d3937263c75",
            "b63d088ed6db4d0a916adf783638be0a",
            "75f9153b219a4be092bd689b641a9fb4",
            "1dd811d94931462db9e76e22e151dc70",
            "826b7ad7653f43429289b874fdbb853e",
            "fb8a81a5e0f24d799c7070165fd7300a",
            "349c69376fd74d14ad9277f2e8368801",
            "0a9c834bce224381ba76509d2ddfa7f6",
            "3cb65073e8c64b7785426202828e0fa6",
            "cbdb6917863a49d9aa77773aa18b9493",
            "8fed3eaea31642ba89da5d15d0e328c8",
            "be27a2c26d154b1a80a7f2373d780000",
            "7a421b04d96f48959e691ac83f8a24fc",
            "a6f60227443d4669b86283e1f246f75f",
            "073142c6268845fa8841f2f21f5f346e",
            "efd8849906d449ad9686456169617781",
            "6341fb0490f945fdb48676c9d89555da",
            "bfe5faafd1cf4f898d56424c1b5b51a5"
          ]
        },
        "id": "wNNc28jVWzK6",
        "outputId": "d2211b67-9a3a-4495-de68-656f60792c12"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c6bf8c6c1f747e5b1a85cdbeafa93d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0a9c834bce224381ba76509d2ddfa7f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Old code using `unsloth`:\n",
        "# tokenizer = FastLanguageModelTokenizer.from_pretrained('model_name')\n",
        "\n",
        "# New code using Hugging Face:\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9b136f79dd7d4ffbba3970535c506ab7",
            "f78176c9bb694a82aaa81e338c5c257b",
            "2e403f81d2b54177a3e900b51585d6ac",
            "c8c725e544d449d58789e8f8700bb5b9",
            "c69490285d61462e928c2b8bb2edaceb",
            "a6cbef9396ef49788b93e8ed6b5e1e55",
            "7bb516b4328c49f6b4c4acf5b112aa69",
            "1aa90b2b95be41049836fb607bc94fe2",
            "a077175ca68546ccaf1f0f3b7302d8c5",
            "1981db5e1629451db9b309bf22ce7a7d",
            "91b7afa719a345aea4eac7e6e75f3330",
            "1644626ec83146de9f5e3ad2bbc4e937",
            "8cbcc71d5a1f4fcfa238c42bf6ca64fe",
            "ef4e56b20a3c4f6ba919100156e2f0b1",
            "1d1d97befddb4de8a7cb5606d9a09b0d",
            "33b250ba2a3c460bac5b1038d47d6e02",
            "ca62a500dc1549df8e85386d0ad2e0fb",
            "f7d185339a1a4d3db9f7c12bcbc72593",
            "a86292940b544fb2a1c285256f4d765f",
            "168588ad75ba4abc8bc262853899b93c",
            "70119988fe8c420ba28903adc2b1f318",
            "b3c2083e19fa497bbca4b175c4c59dcf",
            "38f5211b80af41ccbe5abb1dd2269300",
            "7271586fcafc480882a361a74fcd7b37",
            "b395b65cc4cb4a2c9bde38c977c10f3b",
            "68fc5b39a17d48aeaf8a57b7da035c23",
            "d90f2c0843b644a6bce90edc31ab24a0",
            "0bdb94a4757e4818a703e3a8548d1f11",
            "b9ad8030c62c4bcb998f614d11c7182c",
            "be6943c00db341a98e094359cfc1f7e1",
            "4b97c522995049b4ba94db70b7799c44",
            "f13e39e9dba14a2785ced9161cce9d25",
            "b00ddfd330f64d2a90be58d6afb6a3a4"
          ]
        },
        "id": "GPjP7NLsXMr8",
        "outputId": "2d469893-bc8a-42d4-f1ce-c26deb4dddfe"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b136f79dd7d4ffbba3970535c506ab7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1644626ec83146de9f5e3ad2bbc4e937"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38f5211b80af41ccbe5abb1dd2269300"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "# Example: Loading a pre-trained model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# For example, let's tokenize some input text\n",
        "text = \"Hello, how are you?\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "# Forward pass with the model\n",
        "outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnevTcy2XSEZ",
        "outputId": "e6eaeca7-ce4b-49bd-913f-aa4490429e4d"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SequenceClassifierOutput(loss=None, logits=tensor([[-0.4386, -0.0618]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository to your Colab environment\n",
        "!git clone https://github.com/aaishajalal/RAMQA_updated  # Replace with your repository URL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Sk-Db12rgAR",
        "outputId": "f4679e72-41a0-442a-d04e-2513e15f3419"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RAMQA_updated'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects:  33% (1/3)\rReceiving objects:  66% (2/3)\rReceiving objects: 100% (3/3)\rReceiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the folder path where your code is stored\n",
        "project_folder = '/content/RAMQA'\n",
        "\n",
        "# Define the path to your cloned repository\n",
        "repo_folder = '/content/RAMQA_updated'\n",
        "\n",
        "# Copy the files into the repository directory\n",
        "shutil.copytree(project_folder, os.path.join(repo_folder, 'RAMQA'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Tv0aSTN4rkTp",
        "outputId": "dcb25a97-a0d8-4168-a770-6257775394a6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/RAMQA_updated/RAMQA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nWJ9FOJr7ll"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}